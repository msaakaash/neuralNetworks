# 🧠 Neural Networks

## 📌 Overview  
- This repository contains the implementation of basic neural network algorithms built from scratch (hardcoded), without the use of deep learning libraries such as TensorFlow or PyTorch.
- The goal of this project is to demonstrate the inner workings of neural networks, focusing on their mathematical principles and core components.

## 📂 Repository Structure  
- **activationFunctions.py**
- **multiLayerPerceptron.py**
- **singleLayerPerceptron.py**
 

## 🚀 Getting Started  

### Prerequisites  
To run the notebooks, ensure you have the following installed:  
- Python (>=3.7)  
- NumPy

## 🚀 Installation & Usage

### 1️⃣ Clone the Repository
```bash
git clone https://github.com/msaakaash/neuralNetworks.git
cd neuralNetworks
```

### 2️⃣ Check the Status of Changes
```bash
git status
```
### 3️⃣ Add Files to Staging Area
```bash
git add .
```
### 4️⃣ Commit the Changes
```bash
git commit -m "Added new feature or fixed a bug"
```
### 5️⃣ Push Changes to GitHub
```bash
git push origin main
```

## 🔥 Key Topics Covered  
✔ Single Layer Perceptron  
✔ Multi-Layer Perceptron 

## 🛠️ Future Improvements  
- Implementing Backpropagation
- Explore more on various optimizers  

## 🤝 Contributing  
Contributions are welcome! Feel free to fork the repository, work on new features, and submit pull requests.  

## 📝 License  
This project is licensed under the MIT License.  
