# ğŸ§  Neural Networks

## ğŸ“Œ Overview  
- This repository contains the implementation of basic neural network algorithms built from scratch (hardcoded), without the use of deep learning libraries such as TensorFlow or PyTorch.
- The goal of this project is to demonstrate the inner workings of neural networks, focusing on their mathematical principles and core components.

## ğŸ“‚ Repository Structure  
- **activationFunctions.py**
- **multiLayerPerceptron.py**
- **singleLayerPerceptron.py**
 

## ğŸš€ Getting Started  

### Prerequisites  
To run the notebooks, ensure you have the following installed:  
- Python (>=3.7)  
- NumPy

## ğŸš€ Installation & Usage

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/msaakaash/neuralNetworks.git
cd neuralNetworks
```

### 2ï¸âƒ£ Check the Status of Changes
```bash
git status
```
### 3ï¸âƒ£ Add Files to Staging Area
```bash
git add .
```
### 4ï¸âƒ£ Commit the Changes
```bash
git commit -m "Added new feature or fixed a bug"
```
### 5ï¸âƒ£ Push Changes to GitHub
```bash
git push origin main
```

## ğŸ”¥ Key Topics Covered  
âœ” Single Layer Perceptron  
âœ” Multi-Layer Perceptron 

## ğŸ› ï¸ Future Improvements  
- Implementing Backpropagation
- Explore more on various optimizers  

## ğŸ¤ Contributing  
Contributions are welcome! Feel free to fork the repository, work on new features, and submit pull requests.  

## ğŸ“ License  
This project is licensed under the MIT License.  
